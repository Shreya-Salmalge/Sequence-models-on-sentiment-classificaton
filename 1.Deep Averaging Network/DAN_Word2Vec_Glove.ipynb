{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kGGrncpXSV-1",
    "outputId": "337f5a91-1248-4809-cf60-ad7fb11fcc8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3XJ35te6PYR",
    "outputId": "e59ecd83-ad3b-40a7-8610-a8b1f75fab94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/dlnlpAssign1\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/dlnlpAssign1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-alHHgb9gAgx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Ox0vlHp8Jys",
    "outputId": "ec597d40-78ef-45ee-cba3-18c6128e4dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n",
      "662\n"
     ]
    }
   ],
   "source": [
    "filename1 = 'Train.pos'\n",
    "filename2 = 'Train.neg'\n",
    "filenameTest = 'TestData'\n",
    "\n",
    "with open(filename1, encoding = \"ISO-8859-1\") as my_file:\n",
    "    posSentences = my_file.readlines()\n",
    "# posSentences = posSentences[:100]\n",
    "lenPos = len(posSentences)\n",
    "print(lenPos)\n",
    "\n",
    "with open(filename2, encoding = \"ISO-8859-1\") as my_file:\n",
    "    negSentences = my_file.readlines()\n",
    "# negSentences = negSentences[:100]\n",
    "lenNeg = len(negSentences)\n",
    "print(lenNeg)\n",
    "\n",
    "with open(filenameTest, encoding = \"ISO-8859-1\") as my_file:\n",
    "    testSentences = my_file.readlines()\n",
    "# negSentences = negSentences[:100]\n",
    "lenTest = len(testSentences)\n",
    "print(lenTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cgOdos5_8eQE"
   },
   "outputs": [],
   "source": [
    "def read_glove_vector(glove_vec):\n",
    "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
    "    word_to_vec_map = {}\n",
    "    for line in f:\n",
    "      w_line = line.split()\n",
    "      curr_word = w_line[0]\n",
    "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "\n",
    "  return word_to_vec_map\n",
    "\n",
    "gloveFile = \"glove.6B.200d.txt\"\n",
    "word_to_vec_map = read_glove_vector(gloveFile)\n",
    "# print(word_to_vec_map['rock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "egLStfT1kbh9"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "w2vmodel = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "20kFOXX48OpX"
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "# posSentences = posSentences[:6]\n",
    "# negSentences = negSentences[:6]\n",
    "\n",
    "for sentence in posSentences:\n",
    "    sentence = sentence.translate(table)\n",
    "    words = sentence.strip().split()\n",
    "    # stripped = [w.translate(table) for w in words]\n",
    "    dataset.append(words)\n",
    "\n",
    "for sentence in negSentences:\n",
    "    sentence = sentence.translate(table)\n",
    "    words = sentence.strip().split()\n",
    "    # stripped = [w.translate(table) for w in words]\n",
    "    dataset.append(words)\n",
    "\n",
    "testDataset = []\n",
    "for sentence in testSentences:\n",
    "    sentence = sentence.translate(table)\n",
    "    words = sentence.strip().split()\n",
    "    # stripped = [w.translate(table) for w in words]\n",
    "    testDataset.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGzjs6awTnQI",
    "outputId": "4442b89c-8fe4-4b81-93e4-1bee7e2e0c82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "vecDataset = []\n",
    "# i = 0\n",
    "for lo_words in dataset:\n",
    "  cnt = len(lo_words)\n",
    "  \n",
    "  lo_vecs_glove = [word_to_vec_map['unk'] if x not in word_to_vec_map.keys() else word_to_vec_map[x] for x in lo_words]\n",
    "  sum_vec_glove = sum(lo_vecs_glove)\n",
    "\n",
    "  lo_vecs_w2v = [w2vmodel['unk'] if x not in w2vmodel.wv.vocab else w2vmodel[x] for x in lo_words]\n",
    "  sum_vec_w2v = sum(lo_vecs_w2v)\n",
    "  \n",
    "  sum_vec = np.append(sum_vec_glove,sum_vec_w2v)\n",
    "  vecDataset.append(sum_vec/cnt)\n",
    "\n",
    "testVecDataset = []\n",
    "for lo_words in testDataset:\n",
    "  cnt = len(lo_words)\n",
    "  lo_vecs_glove = [word_to_vec_map['unk'] if x not in word_to_vec_map.keys() else word_to_vec_map[x] for x in lo_words]\n",
    "  sum_vec_glove = sum(lo_vecs_glove)\n",
    "  lo_vecs_w2v = [w2vmodel['unk'] if x not in w2vmodel.wv.vocab else w2vmodel[x] for x in lo_words]\n",
    "  sum_vec_w2v = sum(lo_vecs_w2v)\n",
    "  sum_vec = np.append(sum_vec_glove,sum_vec_w2v)\n",
    "  testVecDataset.append(sum_vec/cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1_oh4BkViI-",
    "outputId": "e709349d-34b1-4fa8-f4e9-e4cd6887e7aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 500])\n",
      "torch.Size([662, 500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_data = torch.tensor(vecDataset, dtype=torch.float)\n",
    "print(x_data.size())\n",
    "\n",
    "x_data_test = torch.tensor(testVecDataset, dtype=torch.float)\n",
    "print(x_data_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYiqXrqyYE0r",
    "outputId": "4c877d7c-b43c-498f-f2aa-bcda75b49b6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1])\n",
      "torch.Size([662, 1])\n"
     ]
    }
   ],
   "source": [
    "shape = (lenPos,1)\n",
    "y1 = torch.ones(shape)\n",
    "y0 = torch.zeros(shape)\n",
    "y = torch.cat((y1,y0))\n",
    "print(y.size())\n",
    "\n",
    "shape1 = (331,1)\n",
    "y1test = torch.ones(shape1)\n",
    "y0test = torch.zeros(shape1)\n",
    "y_test = torch.cat((y1test,y0test))\n",
    "print(y_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0oeefHn4ZFGJ"
   },
   "outputs": [],
   "source": [
    "full_dataset = data_utils.TensorDataset(x_data, y)\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "validation_size = len(full_dataset) - train_size\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(full_dataset, [train_size, validation_size])\n",
    "train_loader = data_utils.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = data_utils.DataLoader(validation_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "testDataset = data_utils.TensorDataset(x_data_test, y_test)\n",
    "test_loader = data_utils.DataLoader(testDataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYOhJ-389IJr",
    "outputId": "c75e6e67-fc21-4387-d3a3-b56dea31375b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Q9aruBp69ZrO"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.hid1 = nn.Linear(500, 500)  \n",
    "    self.hid2 = nn.Linear(500, 300)\n",
    "    self.hid3 = nn.Linear(300, 100)\n",
    "    self.oupt = nn.Linear(100, 1)\n",
    "    self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = torch.relu(self.hid1(x))\n",
    "    z = self.dropout(z) \n",
    "    z = torch.relu(self.hid2(z))\n",
    "    z = self.dropout(z)\n",
    "    z = torch.relu(self.hid3(z))\n",
    "    z = self.dropout(z)\n",
    "    z = torch.sigmoid(self.oupt(z))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1H857f9mABhs"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LDhMHsElAG0W"
   },
   "outputs": [],
   "source": [
    "\n",
    "# average vectors over sentence and convert to tensor\n",
    "# use dataloader\n",
    "# train then - refer to official site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1iVsAwUgTG0l"
   },
   "outputs": [],
   "source": [
    "# print(word_to_vec_map['unk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FSE3xBJOZzge"
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6a_NTvvjbVmE"
   },
   "outputs": [],
   "source": [
    "def validation_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    validation_loss, correct, incorrect = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            validation_loss += loss_fn(pred, y).item()\n",
    "            correct += ((pred>=0.5) == y).type(torch.float).sum().item()\n",
    "            incorrect += ((pred>=0.5) != y).type(torch.float).sum().item()\n",
    "\n",
    "    validation_loss /= num_batches\n",
    "    correct /= size\n",
    "    incorrect /= size\n",
    "    print(f\"validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {validation_loss:>8f} \\n\")\n",
    "    print(f\"Incorrect percentage : \\n Accuracy: {(100*incorrect):>0.1f}%\\n\")\n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lMpzvQkcgJ52"
   },
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    validation_loss, correct, incorrect = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            validation_loss += loss_fn(pred, y).item()\n",
    "            correct += ((pred>=0.5) == y).type(torch.float).sum().item()\n",
    "            incorrect += ((pred>=0.5) != y).type(torch.float).sum().item()\n",
    "\n",
    "    validation_loss /= num_batches\n",
    "    correct /= size\n",
    "    incorrect /= size\n",
    "    print(f\"Test Stats: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {validation_loss:>8f} \\n\")\n",
    "    print(f\"Incorrect percentage : \\n Accuracy: {(100*incorrect):>0.1f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "T6XQFrH6aKpU"
   },
   "outputs": [],
   "source": [
    "def getTrainLoseAndError(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, correct, incorrect = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            train_loss += loss_fn(pred, y).item()\n",
    "            correct += ((pred>=0.5) == y).type(torch.float).sum().item()\n",
    "            incorrect += ((pred>=0.5) != y).type(torch.float).sum().item()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    correct /= size\n",
    "    incorrect /= size\n",
    "    print(f\"Train Error : \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "    print(f\"Incorrect percentage : \\n Accuracy: {(100*incorrect):>0.1f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7S8lj-1Wa41v",
    "outputId": "e0cc175f-7984-4f94-8e08-6a6a618eaf59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the begining :\n",
      "Train Error : \n",
      " Accuracy: 49.9%, Avg loss: 0.693979 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 50.1%\n",
      "\n",
      "validation Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.694338 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 50.0%\n",
      "\n",
      "------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.690249  [    0/ 7500]\n",
      "loss: 0.495395  [ 3200/ 7500]\n",
      "loss: 0.501509  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.525056 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 25.6%\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.470821  [    0/ 7500]\n",
      "loss: 0.515739  [ 3200/ 7500]\n",
      "loss: 0.503476  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.501469 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 25.3%\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.512352  [    0/ 7500]\n",
      "loss: 0.578902  [ 3200/ 7500]\n",
      "loss: 0.511824  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.483976 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.0%\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.419546  [    0/ 7500]\n",
      "loss: 0.389487  [ 3200/ 7500]\n",
      "loss: 0.385248  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.503745 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 24.7%\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.427639  [    0/ 7500]\n",
      "loss: 0.541846  [ 3200/ 7500]\n",
      "loss: 0.436363  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.485240 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.8%\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.447880  [    0/ 7500]\n",
      "loss: 0.435470  [ 3200/ 7500]\n",
      "loss: 0.497222  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.484816 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.0%\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.465829  [    0/ 7500]\n",
      "loss: 0.439278  [ 3200/ 7500]\n",
      "loss: 0.503791  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.490013 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.4%\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.357374  [    0/ 7500]\n",
      "loss: 0.485329  [ 3200/ 7500]\n",
      "loss: 0.536458  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.483194 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 22.9%\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.438860  [    0/ 7500]\n",
      "loss: 0.436016  [ 3200/ 7500]\n",
      "loss: 0.508446  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.476078 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.1%\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.367159  [    0/ 7500]\n",
      "loss: 0.417590  [ 3200/ 7500]\n",
      "loss: 0.326104  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.513501 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.6%\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.407879  [    0/ 7500]\n",
      "loss: 0.473689  [ 3200/ 7500]\n",
      "loss: 0.345417  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.482731 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 24.2%\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.349391  [    0/ 7500]\n",
      "loss: 0.517570  [ 3200/ 7500]\n",
      "loss: 0.383376  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.503251 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.6%\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.491832  [    0/ 7500]\n",
      "loss: 0.414094  [ 3200/ 7500]\n",
      "loss: 0.395415  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.491600 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.6%\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.382872  [    0/ 7500]\n",
      "loss: 0.471749  [ 3200/ 7500]\n",
      "loss: 0.446435  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.512049 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.4%\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.309293  [    0/ 7500]\n",
      "loss: 0.335741  [ 3200/ 7500]\n",
      "loss: 0.382660  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.479480 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.6%\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.462778  [    0/ 7500]\n",
      "loss: 0.375414  [ 3200/ 7500]\n",
      "loss: 0.395759  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.503428 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.0%\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.416145  [    0/ 7500]\n",
      "loss: 0.287477  [ 3200/ 7500]\n",
      "loss: 0.330770  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.505295 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.2%\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.433714  [    0/ 7500]\n",
      "loss: 0.302247  [ 3200/ 7500]\n",
      "loss: 0.237852  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.2%, Avg loss: 1.133975 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.8%\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.354919  [    0/ 7500]\n",
      "loss: 0.454120  [ 3200/ 7500]\n",
      "loss: 0.354615  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.560567 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.5%\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.414929  [    0/ 7500]\n",
      "loss: 0.350274  [ 3200/ 7500]\n",
      "loss: 0.333058  [ 6400/ 7500]\n",
      "validation Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.571415 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 24.4%\n",
      "\n",
      "Done!\n",
      "In the End :\n",
      "Train Error : \n",
      " Accuracy: 83.1%, Avg loss: 0.365663 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 16.9%\n",
      "\n",
      "validation Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.628116 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 24.3%\n",
      "\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #try adagrad too\n",
    "print(\"In the begining :\")\n",
    "getTrainLoseAndError(train_loader, model, loss_fn)\n",
    "validation_loop(validation_loader, model, loss_fn)\n",
    "print(\"------------------\")\n",
    "vLossMin = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    vLoss = validation_loop(validation_loader, model, loss_fn)\n",
    "    if(vLossMin>vLoss):\n",
    "      torch.save(model, \"modelMinLoss.p\")\n",
    "      vLossMin = vLoss\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"In the End :\")\n",
    "getTrainLoseAndError(train_loader, model, loss_fn)\n",
    "validation_loop(validation_loader, model, loss_fn)\n",
    "print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9YHEOoAx0xG",
    "outputId": "0aa70f10-302c-4710-fcfd-e92ae659bfcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Stats: \n",
      " Accuracy: 76.1%, Avg loss: 0.468983 \n",
      "\n",
      "Incorrect percentage : \n",
      " Accuracy: 23.9%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# torch.save(model, \"model1.p\")\n",
    "model = torch.load(\"modelMinLoss.p\")\n",
    "test_loop(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "IoZq9MYKfxSU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of dlnlpAssignment1_v3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
